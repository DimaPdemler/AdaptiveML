{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.MNIST(root = '/Users/dimademler/Desktop/me-Programming/pytorch',\n",
    "                                           train = True,\n",
    "                                           transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root = '/Users/dimademler/Desktop/me-Programming/pytorch',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "augmented_train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                           train = True,\n",
    "                                           transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.RandomVerticalFlip(p=1),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "augmented_train_loader = torch.utils.data.DataLoader(dataset = augmented_train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "augmented_test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.RandomVerticalFlip(p=1),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "\n",
    "augmented_test_loader = torch.utils.data.DataLoader(dataset = augmented_test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "#Setting the loss function\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "#this is defined to print how many steps are remaining when training\n",
    "total_step = len(train_loader)\n",
    "\n",
    "def train(model,train_loader,test_loader,num_epochs,optimizer):\n",
    "  total_step = len(train_loader)\n",
    "  for epoch in range(num_epochs):\n",
    "      for i, (images, labels) in enumerate(train_loader):  \n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          #Forward pass\n",
    "          outputs = model(images)\n",
    "          loss = cost(outputs, labels)\n",
    "            \n",
    "          # Backward and optimize\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "              \n",
    "          if (i+1) % 400 == 0:\n",
    "              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                        .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "  \n",
    "def test(model, test_loader):\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(test_loader):  \n",
    "            test_output = model(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "    return accuracy\n",
    "\n",
    "          \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, max_growth):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc1 = nn.Linear(400,500+max_growth)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(500+max_growth,100+max_growth)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(100+max_growth,10)\n",
    "\n",
    "        #Custom Functionality\n",
    "        self.max_growth = max_growth\n",
    "        previous_module = self.parameters_to_prune()[0][0]\n",
    "\n",
    "        for module, name in self.parameters_to_prune()[1:]:\n",
    "\n",
    "          #Prune incoming weights (Previous layers outgoing weights)\n",
    "          if previous_module != None:\n",
    "            mask = torch.ones(np.shape(previous_module.weight))\n",
    "            mask[-max_growth:,:] = 0\n",
    "            prune.custom_from_mask(previous_module, name, mask)\n",
    "            \n",
    "          #Prune outgoing weights\n",
    "          mask = torch.ones(np.shape(module.weight))\n",
    "          mask[:,-max_growth:] = 0\n",
    "          prune.custom_from_mask(module, name, mask)\n",
    "\n",
    "          previous_module = module  #save layer for next iteration\n",
    "        \n",
    "\n",
    "    def parameters_to_prune(self):\n",
    "        return ((self.fc1, 'weight'),\n",
    "                (self.fc2, 'weight'),\n",
    "                (self.fc3, 'weight'),) \n",
    "    #End Custom Functionality\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All in One Method to Find Lottery Tickets given a model and dataset, saves models in shared drive\n",
    "def find_ticket(model, name, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 10, learning_rate = .001, prune_amount = .2, k = 3):\n",
    "  \n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  #If training has already been saved\n",
    "  try:\n",
    "    model.load_state_dict(torch.load('/content/drive/MyDrive/AdaptiveML/models/'+ name + '_RewindWeights' + '_' + str(k)))\n",
    "  except:\n",
    "    train(model, train_loader,test_loader,num_epochs = k, optimizer = optimizer)  #Save Kth epoch model\n",
    "    torch.save(model.state_dict(), '/content/drive/MyDrive/AdaptiveML/models/' + name + '_RewindWeights' + '_' + str(k))\n",
    "\n",
    "  model_rewind = LeNet(max_growth = model.max_growth) #Save as separate model so we can rewind our weights back to this\n",
    "  model_rewind.load_state_dict(torch.load('/content/drive/MyDrive/AdaptiveML/models/'+ name + '_RewindWeights' + '_' + str(k)))\n",
    "\n",
    "  train(model, train_loader,test_loader,num_epochs = num_epochs - k, optimizer = optimizer) #Finish off training\n",
    "  accuracy = []\n",
    "\n",
    "  for i in range(start_iter, end_iter): \n",
    "    #Prune\n",
    "    prune.global_unstructured(model.parameters_to_prune(),pruning_method=prune.L1Unstructured,amount=prune_amount,)\n",
    "    \n",
    "    #Rewind Weights\n",
    "    for idx, (module, _) in enumerate(model.parameters_to_prune()):\n",
    "      with torch.no_grad():\n",
    "        module_rewind = model_rewind.parameters_to_prune()[idx][0]\n",
    "        module.weight_orig.copy_(module_rewind.weight)\n",
    "\n",
    "    print(\n",
    "    \"Global Sparsity: {:.2f}%\".format(\n",
    "        100. * (float(torch.sum(model.fc3.weight == 0)) + float(torch.sum(model.fc1.weight == 0)) + float(torch.sum(model.fc2.weight == 0)))\n",
    "        / (float(model.fc3.weight.nelement()) + float(model.fc1.weight.nelement()) + float(model.fc2.weight.nelement()))\n",
    "    )\n",
    "    )\n",
    "    \n",
    "    #Train\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train(model, train_loader,test_loader,num_epochs = num_epochs, optimizer = optimizer)\n",
    "    accuracy.append(test(model, test_loader))\n",
    "\n",
    "    plt.plot(np.arange(len(accuracy)), accuracy)\n",
    "    plt.show()\n",
    "    print('Saving iteration ', str(i+1))\n",
    "    torch.save(model.state_dict(), '/content/drive/MyDrive/AdaptiveML/models/' + name + '_iter' + str(i+1)) \n",
    "\n",
    "def grow(model, parameters_to_prune, amount):\n",
    "  previous_module = parameters_to_prune[0][0]\n",
    "\n",
    "  for module, name in parameters_to_prune[1:]:\n",
    "    mask = module.get_buffer('weight_mask').data\n",
    "    #Pick Suitable Locations\n",
    "    omega = []\n",
    "    for idx, val in enumerate(torch.sum(mask, dim = 0)): \n",
    "      if val == 0:\n",
    "        omega.append(idx)\n",
    "\n",
    "    indices = np.random.choice(omega, size = min(len(omega), amount), replace = False)\n",
    "    \n",
    "    #Grow at these indices\n",
    "    module.get_buffer('weight_mask')[:,indices] = 1\n",
    "    prune.custom_from_mask(module,'weight', torch.ones(module.weight.size()))\n",
    "\n",
    "    previous_module.get_buffer('weight_mask')[indices,:] = 1\n",
    "    prune.custom_from_mask(previous_module,'weight', torch.ones(previous_module.weight.size()))  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "065903266eccafe089f2ae6c8a75912f88be57d9e6a3d93d1ff3f958981ce42e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
