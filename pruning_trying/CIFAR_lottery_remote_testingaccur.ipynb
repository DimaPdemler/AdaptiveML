{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9c8c054c90>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy\n",
    "\n",
    "# from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "class LeNet(nn.Module):\n",
    "    def __init__(self, max_growth):\n",
    "        super(LeNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 6, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(6),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size = 2, stride = 2))\n",
    "        self.fc1 = nn.Linear(400,500+max_growth)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(500+max_growth,100+max_growth)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(100+max_growth,10)\n",
    "\n",
    "        #Custom Functionality\n",
    "        self.max_growth = max_growth\n",
    "        previous_module = self.parameters_to_prune()[0][0]\n",
    "\n",
    "        for module, name in self.parameters_to_prune()[1:]:\n",
    "\n",
    "          #Prune incoming weights (Previous layers outgoing weights)\n",
    "          if previous_module != None:\n",
    "            mask = torch.ones(np.shape(previous_module.weight))\n",
    "            mask[-max_growth:,:] = 0\n",
    "            prune.custom_from_mask(previous_module, name, mask)\n",
    "            \n",
    "          #Prune outgoing weights\n",
    "          mask = torch.ones(np.shape(module.weight))\n",
    "          mask[:,-max_growth:] = 0\n",
    "          prune.custom_from_mask(module, name, mask)\n",
    "\n",
    "          previous_module = module  #save layer for next iteration\n",
    "        \n",
    "\n",
    "    def parameters_to_prune(self):\n",
    "        return ((self.fc1, 'weight'),\n",
    "                (self.fc2, 'weight'),\n",
    "                (self.fc3, 'weight'),) \n",
    "    #End Custom Functionality\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.reshape(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu1(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Define relevant variables for the ML task\n",
    "batch_size = 64\n",
    "num_classes = 10\n",
    "learning_rate = 0.001\n",
    "\n",
    "#Loading the dataset and preprocessing\n",
    "train_dataset = torchvision.datasets.CIFAR10(root = 'private/cifar/',\n",
    "                                           train = True,\n",
    "                                           transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root = 'private/cifar/',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "augmented_train_dataset = torchvision.datasets.CIFAR10(root = 'private/cifar/',\n",
    "                                           train = True,\n",
    "                                           transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.RandomVerticalFlip(p=1),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "\n",
    "augmented_train_loader = torch.utils.data.DataLoader(dataset = augmented_train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "augmented_test_dataset = torchvision.datasets.CIFAR10(root = 'private/cifar/',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.RandomVerticalFlip(p=1),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "\n",
    "augmented_test_loader = torch.utils.data.DataLoader(dataset = augmented_test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "\n",
    "\n",
    "# train_dataset, test_dataset = train_dataset.cuda(), test_dataset.cuda()\n",
    "\n",
    "#Setting the loss function\n",
    "cost = nn.CrossEntropyLoss()\n",
    "\n",
    "#this is defined to print how many steps are remaining when training\n",
    "total_step = len(train_loader)\n",
    "\n",
    "def train(model,train_loader,test_loader,num_epochs,optimizer):\n",
    "  accuracy=[]\n",
    "  model.to(device)\n",
    "  total_step = len(train_loader)\n",
    "  for epoch in range(num_epochs):\n",
    "      accuracy.append(test(model,test_loader))\n",
    "    #   print(accuracy)\n",
    "      for i, (images, labels) in enumerate(train_loader): \n",
    "          \n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          #Forward pass\n",
    "          outputs = model(images)\n",
    "          loss = cost(outputs, labels)\n",
    "            \n",
    "          # Backward and optimize\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "              \n",
    "          if (i+1) % 400 == 0:\n",
    "              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                        .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "  return accuracy\n",
    "  \n",
    "def test(model, test_loader):\n",
    "    # print(\"model: \",type(model))\n",
    "    # print(\"test_loader: \",type(test_loader))\n",
    "    # model.to(device)\n",
    "    # test_loader.to(device)\n",
    "    # Test the model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for i, (images, labels) in enumerate(test_loader): \n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            # model=model.to(device)\n",
    "            test_output = model(images)\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "            accuracy = (pred_y == labels).sum().item() / float(labels.size(0))\n",
    "\n",
    "    print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#All in One Method to Find Lottery Tickets given a model and dataset, saves models in shared drive\n",
    "def find_ticket(model, name, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 10, learning_rate = .001, prune_amount = .2, k = 3):\n",
    "  model.to(device)\n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "  #If training has already been saved\n",
    "  try:\n",
    "    model.load_state_dict(torch.load('private/cifar/models/'+ name + '_RewindWeights' + '_' + str(k)))\n",
    "  except:\n",
    "    train(model, train_loader,test_loader,num_epochs = k, optimizer = optimizer)  #Save Kth epoch model\n",
    "    torch.save(model.state_dict(), 'private/cifar/models/' + name + '_RewindWeights' + '_' + str(k))\n",
    "\n",
    "  model_rewind = LeNet(max_growth = model.max_growth) #Save as separate model so we can rewind our weights back to this\n",
    "  model_rewind.load_state_dict(torch.load('private/cifar/models/'+ name + '_RewindWeights' + '_' + str(k)))\n",
    "\n",
    "  train(model, train_loader,test_loader,num_epochs = num_epochs - k, optimizer = optimizer) #Finish off training\n",
    "  accuracy = []\n",
    "\n",
    "  for i in range(start_iter, end_iter): \n",
    "    #Prune\n",
    "    prune.global_unstructured(model.parameters_to_prune(),pruning_method=prune.L1Unstructured,amount=prune_amount,)\n",
    "    \n",
    "    #Rewind Weights\n",
    "    for idx, (module, _) in enumerate(model.parameters_to_prune()):\n",
    "      with torch.no_grad():\n",
    "        module_rewind = model_rewind.parameters_to_prune()[idx][0]\n",
    "        module.weight_orig.copy_(module_rewind.weight)\n",
    "\n",
    "    print(\n",
    "    \"Global Sparsity: {:.2f}%\".format(\n",
    "        100. * (float(torch.sum(model.fc3.weight == 0)) + float(torch.sum(model.fc1.weight == 0)) + float(torch.sum(model.fc2.weight == 0)))\n",
    "        / (float(model.fc3.weight.nelement()) + float(model.fc1.weight.nelement()) + float(model.fc2.weight.nelement()))\n",
    "    )\n",
    "    )\n",
    "    \n",
    "    #Train\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    train(model, train_loader,test_loader,num_epochs = num_epochs, optimizer = optimizer)\n",
    "    accuracy.append(test(model, test_loader))\n",
    "\n",
    "    plt.plot(np.arange(len(accuracy)), accuracy)\n",
    "    plt.show()\n",
    "    print('Saving iteration ', str(i+1))\n",
    "    torch.save(model.state_dict(), 'private/cifar/models/' + name + '_iter' + str(i+1)) \n",
    "\n",
    "def grow(model, parameters_to_prune, amount):\n",
    "  previous_module = parameters_to_prune[0][0]\n",
    "\n",
    "  for module, name in parameters_to_prune[1:]:\n",
    "    mask = module.get_buffer('weight_mask').data\n",
    "    #Pick Suitable Locations\n",
    "    omega = []\n",
    "    for idx, val in enumerate(torch.sum(mask, dim = 0)): \n",
    "      if val == 0:\n",
    "        omega.append(idx)\n",
    "\n",
    "    indices = np.random.choice(omega, size = min(len(omega), amount), replace = False)\n",
    "    \n",
    "    #Grow at these indices\n",
    "    module.get_buffer('weight_mask')[:,indices] = 1\n",
    "    prune.custom_from_mask(module,'weight', torch.ones(module.weight.size()))\n",
    "\n",
    "    previous_module.get_buffer('weight_mask')[indices,:] = 1\n",
    "    prune.custom_from_mask(previous_module,'weight', torch.ones(previous_module.weight.size()))  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Adam gradient descent ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 0.06\n",
      "Epoch [1/50], Step [400/782], Loss: 1.5729\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n",
      "Epoch [2/50], Step [400/782], Loss: 1.3458\n",
      "Test Accuracy of the model on the 10000 test images: 0.44\n",
      "Epoch [3/50], Step [400/782], Loss: 1.0816\n",
      "Test Accuracy of the model on the 10000 test images: 0.69\n",
      "Epoch [4/50], Step [400/782], Loss: 1.0190\n",
      "Test Accuracy of the model on the 10000 test images: 0.69\n",
      "Epoch [5/50], Step [400/782], Loss: 1.1324\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [6/50], Step [400/782], Loss: 1.0795\n",
      "Test Accuracy of the model on the 10000 test images: 0.44\n",
      "Epoch [7/50], Step [400/782], Loss: 0.6320\n",
      "Test Accuracy of the model on the 10000 test images: 0.44\n",
      "Epoch [8/50], Step [400/782], Loss: 0.4996\n",
      "Test Accuracy of the model on the 10000 test images: 0.75\n",
      "Epoch [9/50], Step [400/782], Loss: 0.6284\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n",
      "Epoch [10/50], Step [400/782], Loss: 0.8106\n",
      "Test Accuracy of the model on the 10000 test images: 1.00\n",
      "Epoch [11/50], Step [400/782], Loss: 0.5018\n",
      "Test Accuracy of the model on the 10000 test images: 0.75\n",
      "Epoch [12/50], Step [400/782], Loss: 0.4475\n",
      "Test Accuracy of the model on the 10000 test images: 0.69\n",
      "Epoch [13/50], Step [400/782], Loss: 0.4212\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [14/50], Step [400/782], Loss: 0.2091\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [15/50], Step [400/782], Loss: 0.3162\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [16/50], Step [400/782], Loss: 0.2067\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [17/50], Step [400/782], Loss: 0.3672\n",
      "Test Accuracy of the model on the 10000 test images: 0.56\n",
      "Epoch [18/50], Step [400/782], Loss: 0.2234\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [19/50], Step [400/782], Loss: 0.4846\n",
      "Test Accuracy of the model on the 10000 test images: 0.88\n",
      "Epoch [20/50], Step [400/782], Loss: 0.2056\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n",
      "Epoch [21/50], Step [400/782], Loss: 0.2537\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [22/50], Step [400/782], Loss: 0.2141\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [23/50], Step [400/782], Loss: 0.1133\n",
      "Test Accuracy of the model on the 10000 test images: 0.56\n",
      "Epoch [24/50], Step [400/782], Loss: 0.3064\n",
      "Test Accuracy of the model on the 10000 test images: 0.44\n",
      "Epoch [25/50], Step [400/782], Loss: 0.1272\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [26/50], Step [400/782], Loss: 0.1240\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [27/50], Step [400/782], Loss: 0.2027\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n",
      "Epoch [28/50], Step [400/782], Loss: 0.1195\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [29/50], Step [400/782], Loss: 0.1744\n",
      "Test Accuracy of the model on the 10000 test images: 0.44\n",
      "Epoch [30/50], Step [400/782], Loss: 0.1546\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n",
      "Epoch [31/50], Step [400/782], Loss: 0.1541\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n",
      "Epoch [32/50], Step [400/782], Loss: 0.1460\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [33/50], Step [400/782], Loss: 0.2159\n",
      "Test Accuracy of the model on the 10000 test images: 0.44\n",
      "Epoch [34/50], Step [400/782], Loss: 0.0340\n",
      "Test Accuracy of the model on the 10000 test images: 0.75\n",
      "Epoch [35/50], Step [400/782], Loss: 0.0874\n",
      "Test Accuracy of the model on the 10000 test images: 0.56\n",
      "Epoch [36/50], Step [400/782], Loss: 0.3151\n",
      "Test Accuracy of the model on the 10000 test images: 0.44\n",
      "Epoch [37/50], Step [400/782], Loss: 0.0391\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [38/50], Step [400/782], Loss: 0.0308\n",
      "Test Accuracy of the model on the 10000 test images: 0.75\n",
      "Epoch [39/50], Step [400/782], Loss: 0.0579\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [40/50], Step [400/782], Loss: 0.0619\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [41/50], Step [400/782], Loss: 0.1904\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [42/50], Step [400/782], Loss: 0.0321\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n",
      "Epoch [43/50], Step [400/782], Loss: 0.0213\n",
      "Test Accuracy of the model on the 10000 test images: 0.69\n",
      "Epoch [44/50], Step [400/782], Loss: 0.0646\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [45/50], Step [400/782], Loss: 0.0655\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n",
      "Epoch [46/50], Step [400/782], Loss: 0.0793\n",
      "Test Accuracy of the model on the 10000 test images: 0.75\n",
      "Epoch [47/50], Step [400/782], Loss: 0.1606\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n",
      "Epoch [48/50], Step [400/782], Loss: 0.1162\n",
      "Test Accuracy of the model on the 10000 test images: 0.62\n",
      "Epoch [49/50], Step [400/782], Loss: 0.0955\n",
      "Test Accuracy of the model on the 10000 test images: 0.56\n",
      "Epoch [50/50], Step [400/782], Loss: 0.1072\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_growth = 20\n",
    "num_epochs = 50\n",
    "gamma = 10 #num new nodes on first growth\n",
    "\n",
    "model2 = LeNet(max_growth = max_growth)\n",
    "model2=model2.to(device)\n",
    "optimizer = torch.optim.Adam(model2.parameters(), lr=learning_rate)\n",
    "\n",
    "accur=train(model2, train_loader,test_loader,num_epochs, optimizer = optimizer)\n",
    "\n",
    "epoch=np.linspace(1,num_epochs,num_epochs)\n",
    "plt.plot(epoch,accur)\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Accuracy vs Epoch')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model:  <class '__main__.LeNet'>\n",
      "test_loader:  <class 'torch.utils.data.dataloader.DataLoader'>\n",
      "Test Accuracy of the model on the 10000 test images: 0.50\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(model2,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/7], Step [400/782], Loss: 1.3490\n",
      "Epoch [2/7], Step [400/782], Loss: 0.8731\n",
      "Epoch [3/7], Step [400/782], Loss: 0.9381\n",
      "Epoch [4/7], Step [400/782], Loss: 1.0673\n",
      "Epoch [5/7], Step [400/782], Loss: 0.4895\n",
      "Epoch [6/7], Step [400/782], Loss: 0.5540\n",
      "Epoch [7/7], Step [400/782], Loss: 0.7648\n",
      "Global Sparsity: 33.95%\n",
      "Epoch [1/10], Step [400/782], Loss: 1.4555\n",
      "Epoch [2/10], Step [400/782], Loss: 0.9139\n",
      "Epoch [3/10], Step [400/782], Loss: 1.0598\n",
      "Epoch [4/10], Step [400/782], Loss: 0.9267\n",
      "Epoch [5/10], Step [400/782], Loss: 0.8045\n",
      "Epoch [6/10], Step [400/782], Loss: 0.4943\n",
      "Epoch [7/10], Step [400/782], Loss: 0.6718\n",
      "Epoch [8/10], Step [400/782], Loss: 0.5182\n",
      "Epoch [9/10], Step [400/782], Loss: 0.4728\n",
      "Epoch [10/10], Step [400/782], Loss: 0.4618\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_412/769560156.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLeNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_growth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_growth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfind_ticket\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'CIFAR10'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_412/1707469776.py\u001b[0m in \u001b[0;36mfind_ticket\u001b[0;34m(model, name, train_loader, test_loader, start_iter, end_iter, num_epochs, learning_rate, prune_amount, k)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m     \u001b[0maccuracy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_412/2112805123.py\u001b[0m in \u001b[0;36mtest\u001b[0;34m(model, test_loader)\u001b[0m\n\u001b[1;32m     98\u001b[0m         \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mtest_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m             \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_412/2254171993.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1050\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1051\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1052\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    437\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 439\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    440\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    }
   ],
   "source": [
    "#Generate Tickets\n",
    "\n",
    "max_growth = 50\n",
    "model = LeNet(max_growth = max_growth)\n",
    "find_ticket(model, 'CIFAR10', train_loader, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
