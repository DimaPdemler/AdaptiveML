{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.utils.prune as prune\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "    def __init__(self, in_channels, out_channels, i_downsample=None, stride=1):\n",
    "\n",
    "        super(Bottleneck, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(out_channels, out_channels*self.expansion, kernel_size=1, stride=1, padding=0)\n",
    "        self.batch_norm3 = nn.BatchNorm2d(out_channels*self.expansion)\n",
    "        \n",
    "        self.i_downsample = i_downsample\n",
    "        self.stride = stride\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        self.parameters_to_prune = [\n",
    "            (self.conv1, 'weight'),\n",
    "            (self.conv2, 'weight'),\n",
    "            (self.conv3, 'weight'),\n",
    "        ]\n",
    "\n",
    "        for module, name in self.parameters_to_prune:\n",
    "          mask = torch.ones(np.shape(module.weight))\n",
    "          mask[:,:(np.shape(mask)[1]//5),:] = 0 #Prune input channel\n",
    "          mask[:(np.shape(mask)[0]//5),:,:] = 0 #Prune output channel\n",
    "          prune.custom_from_mask(module, name, mask)\n",
    "\n",
    "        \n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x.clone()\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        \n",
    "        x = self.relu(self.batch_norm2(self.conv2(x)))\n",
    "        \n",
    "        x = self.conv3(x)\n",
    "        x = self.batch_norm3(x)\n",
    "        \n",
    "        #downsample if needed\n",
    "        if self.i_downsample is not None:\n",
    "            identity = self.i_downsample(identity)\n",
    "        #add identity\n",
    "        x+=identity\n",
    "        x=self.relu(x)\n",
    "        \n",
    "        return x\n",
    "       \n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, ResBlock, layer_list, num_classes, num_channels=3):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64 *5//4\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(num_channels, 64*5//4, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        mask = torch.ones(np.shape(self.conv1.weight))\n",
    "        mask[:(np.shape(mask)[0]//5),:,:] = 0 #Prune output channel's new growth\n",
    "        prune.custom_from_mask(self.conv1, 'weight', mask)\n",
    "\n",
    "        self.batch_norm1 = nn.BatchNorm2d(64*5//4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size = 3, stride=2, padding=1)\n",
    "        \n",
    "        self.layer1 = self._make_layer(ResBlock, layer_list[0], planes=64*5//4)\n",
    "        self.layer2 = self._make_layer(ResBlock, layer_list[1], planes=128*5//4, stride=2)\n",
    "        self.layer3 = self._make_layer(ResBlock, layer_list[2], planes=256*5//4, stride=2)\n",
    "        self.layer4 = self._make_layer(ResBlock, layer_list[3], planes=512*5//4, stride=2)\n",
    "        \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.fc = nn.Linear(512*5//4*ResBlock.expansion, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.batch_norm1(self.conv1(x)))\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        \n",
    "        x = self.avgpool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "    def parameters_to_prune(self):\n",
    "        p = [(self.conv1, 'weight')]\n",
    "        for layer in [self.layer1,self.layer2, self.layer3,self.layer4]:\n",
    "         for module in layer:\n",
    "           p = p + module.parameters_to_prune\n",
    "        return  p\n",
    "        \n",
    "    def _make_layer(self, ResBlock, blocks, planes, stride=1):\n",
    "        ii_downsample = None\n",
    "        layers = []\n",
    "        \n",
    "        if stride != 1 or self.in_channels != planes*ResBlock.expansion:\n",
    "            ii_downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.in_channels, planes*ResBlock.expansion, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(planes*ResBlock.expansion)\n",
    "            )\n",
    "            \n",
    "        layers.append(ResBlock(self.in_channels, planes, i_downsample=ii_downsample, stride=stride))\n",
    "        self.in_channels = planes*ResBlock.expansion\n",
    "        \n",
    "        for i in range(blocks-1):\n",
    "            layers.append(ResBlock(self.in_channels, planes))\n",
    "            \n",
    "        return nn.Sequential(*layers)\n",
    "       \n",
    "def ResNet50(num_classes, channels=3):\n",
    "    return ResNet(Bottleneck, [3,4,6,3], num_classes, channels)\n",
    "\n",
    "# Define relevant variables for the ML task\n",
    "batch_size = 512\n",
    "num_classes = 10\n",
    "learning_rate = 0.0003\n",
    "weight_decay = .0001\n",
    "\n",
    "def sparsity_print(model):\n",
    "  zero = total = 0\n",
    "  for module, _ in model.parameters_to_prune():\n",
    "    zero += float(torch.sum(module.weight == 0))\n",
    "    total += float(module.weight.nelement())\n",
    "  print('Number of Zero Weights:', zero)\n",
    "  print('Total Number of Weights:', total)\n",
    "  print('Sparsity with growth:', zero/total)\n",
    "\n",
    "def train(model,train_loader,test_loader,num_epochs,optimizer):\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "  cost = nn.CrossEntropyLoss()\n",
    "  scheduler = MultiStepLR(optimizer, milestones=[50,65,80], gamma=.1)\n",
    "  total_step = len(train_loader)\n",
    "  for epoch in range(num_epochs):\n",
    "      \n",
    "      for i, (images, labels) in enumerate(train_loader):  \n",
    "          images = images.to(device)\n",
    "          labels = labels.to(device)\n",
    "          \n",
    "          #Forward pass\n",
    "          outputs = model(images)\n",
    "          loss = cost(outputs, labels)\n",
    "            \n",
    "          # Backward and optimize\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "              \n",
    "          if (i+1) % 400 == 0:\n",
    "              print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                        .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "              \n",
    "      scheduler.step()\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n",
    "  # Test the model\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      correct = 0\n",
    "      total = 0\n",
    "      for i, (images, labels) in enumerate(test_loader): \n",
    "          images, labels = images.to(device), labels.to(device)\n",
    "          test_output = model(images)\n",
    "          pred_y = torch.max(test_output, 1)[1].data.squeeze()\n",
    "          correct += (pred_y == labels).sum().item()\n",
    "          total += labels.size(0)\n",
    "      accuracy = correct / total\n",
    "\n",
    "  print('Test Accuracy of the model on the 10000 test images: ', accuracy)\n",
    "  return accuracy\n",
    "\n",
    "def find_ticket(model, name, location, train_loader, test_loader, start_iter = 0, end_iter = 30, num_epochs = 90, learning_rate = .001, prune_amount = .2, k = 1):\n",
    "  \n",
    "  optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "  accuracy = []\n",
    "  #If training has already been saved\n",
    "  try:\n",
    "    model.load_state_dict(torch.load(location + name + '_RewindWeights' + '_' + str(k)))\n",
    "  except:\n",
    "    train(model, train_loader,test_loader,num_epochs = k, optimizer = optimizer)  #Save Kth epoch model\n",
    "    torch.save(model.state_dict(), location + name + '_RewindWeights' + '_' + str(k))\n",
    "\n",
    "  model_rewind = ResNet50(num_classes = 10,channels = 1) #Save as separate model so we can rewind our weights back to this \n",
    "  model_rewind.load_state_dict(torch.load(location+ name + '_RewindWeights' + '_' + str(k)))\n",
    "\n",
    "  if start_iter == 0:\n",
    "    train(model, train_loader,test_loader,num_epochs = num_epochs - k, optimizer = optimizer) #Finish off training\n",
    "  else:\n",
    "    model.load_state_dict(torch.load(location + name + '_iter' + str(start_iter)))\n",
    "\n",
    "  for i in range(start_iter, end_iter): \n",
    "    print('Rewinding Iter:', i)\n",
    "    #Prune\n",
    "    prune.global_unstructured(model.parameters_to_prune(),pruning_method=prune.L1Unstructured,amount=prune_amount,)\n",
    "    \n",
    "    #Rewind Weights\n",
    "    for idx, (module, _) in enumerate(model.parameters_to_prune()):\n",
    "      with torch.no_grad():\n",
    "        module_rewind = model_rewind.parameters_to_prune()[idx][0]\n",
    "        module.weight_orig.copy_(module_rewind.weight)\n",
    "    \n",
    "    \n",
    "    #Train\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay = weight_decay)\n",
    "    train(model, train_loader,test_loader,num_epochs = num_epochs, optimizer = optimizer)\n",
    "    accuracy.append(test(model, test_loader, device))\n",
    "\n",
    "    plt.plot(np.arange(len(accuracy)), accuracy)\n",
    "    plt.show()\n",
    "\n",
    "    sparsity_print(model)\n",
    "    print('Saving iteration ', str(i+1))\n",
    "    torch.save(model.state_dict(), location + name + '_iter' + str(i+1)) \n",
    "\n",
    "def grow(model, amount, device):\n",
    "  previous_module = model.parameters_to_prune()[0][0]\n",
    "\n",
    "  for i, (module, name) in enumerate(model.parameters_to_prune()[1:]):\n",
    "    mask = module.get_buffer('weight_mask').data\n",
    "    #Pick Suitable Locations\n",
    "    omega = []\n",
    "    out_channels = mask.sum(dim=(0,2,3))\n",
    "    for idx, val in enumerate(out_channels):\n",
    "      if val == 0:\n",
    "        omega.append(idx)\n",
    "\n",
    "    indices = np.random.choice(omega, size = min(len(omega), amount[i]), replace = False)\n",
    "    \n",
    "    #Grow at these indices\n",
    "    #print(i, module.weight.size())\n",
    "    module.get_buffer('weight_mask')[:,indices] = 1\n",
    "    prune.custom_from_mask(module,'weight', torch.ones(module.weight.size(), device = device))\n",
    "    \n",
    "    previous_module.get_buffer('weight_mask')[indices,:] = 1\n",
    "    prune.custom_from_mask(previous_module,'weight', torch.ones(previous_module.weight.size(), device = device))  \n",
    "    previous_module = module\n",
    "\n",
    "def loss(model, val_loader,error_weight, structure_weight, device):\n",
    "  error = 1-test(model, val_loader, device) #should be validation set, but for now we will use test set\n",
    "\n",
    "  params = 0\n",
    "  total_params = 0\n",
    "  for module,_ in model.parameters_to_prune():\n",
    "    params += float(torch.sum(module.weight == 0))\n",
    "    total_params += float(module.weight.nelement())\n",
    "  structure = 1 - params / total_params  #uses sparsity at the moment\n",
    "  print('Structure: ', structure,', Error: ', error)\n",
    "  return structure_weight * structure + error_weight * error \n",
    "\n",
    "def acceptance(current_loss, new_loss, t,d):\n",
    "  p = math.exp(-1*(new_loss - current_loss) / cooling_schedule(t,d))\n",
    "  return np.random.uniform() < p\n",
    "    \n",
    "def cooling_schedule(t,d):\n",
    "  return d / math.log(t+1)\n",
    "\n",
    "#returns module count - 1 long array\n",
    "def sample_amount(model,t,T):\n",
    "  amount = []\n",
    "  prev_zero = float(torch.sum(model.parameters_to_prune()[0][0].weight == 0))\n",
    "  prev_total = float(model.parameters_to_prune()[0][0].weight.nelement())\n",
    "  for module, _ in model.parameters_to_prune()[1:]:\n",
    "    zero = float(torch.sum(module.weight == 0))\n",
    "    total = float(module.weight.nelement())\n",
    "    layer_sparsity = (prev_zero+zero) / (prev_total+total)\n",
    "    amount.append(get_amount(((T-t) / (50*T))**2,torch.where(module.weight.sum(dim=tuple(range(1, module.weight.dim()))) == 0)[0].size()[0]))\n",
    "    prev_zero = zero\n",
    "    prev_total = total\n",
    "  return amount\n",
    "\n",
    "#given the probability of growth, it samples to represent k-many nodes to grow\n",
    "def get_amount(p,max):\n",
    "  count = 0\n",
    "  for _ in range(max):\n",
    "    if np.random.uniform() < p:\n",
    "      count += 1\n",
    "  return count\n",
    "\n",
    "#Currently 20 epochs for hyper param tuning, but lets turn it up to 90 once we done\n",
    "def simulated_annealing(model, device, train_loader, val_loader, name, d = 5, T = 30, prune_amount = .2, num_epochs = 20, structure_weight = 1, error_weight = 5):\n",
    "  \n",
    "  model.to(device)\n",
    "\n",
    "  current_model = model.to(device)\n",
    "  current_loss = loss(model, val_loader, error_weight, structure_weight, device) #CHANGE THIS TO VALIDATION LOSS\n",
    "  losses = []\n",
    "  for t in range(1,T+1):\n",
    "\n",
    "    amount = sample_amount(current_model,t,T)\n",
    "\n",
    "    #Create next model\n",
    "    next_model = ResNet50(num_classes = 10,channels = 1).to(device)\n",
    "    next_model.load_state_dict(current_model.state_dict())\n",
    "    grow(next_model, amount, device)\n",
    "\n",
    "\n",
    "    optimizer = torch.optim.Adam(next_model.parameters(), lr=learning_rate)\n",
    "    train(next_model, train_loader,val_loader,num_epochs = num_epochs // 2, optimizer = optimizer)\n",
    "    prune.global_unstructured(next_model.parameters_to_prune(),pruning_method=prune.L1Unstructured,amount=prune_amount)\n",
    "    train(next_model, train_loader,val_loader,num_epochs = num_epochs, optimizer = optimizer)\n",
    "\n",
    "    next_loss = loss(next_model, val_loader, error_weight, structure_weight, device) #CHANGE THIS TO VALIDATION LOSS\n",
    "    print('Next_Loss at time ', t, ' is: ',next_loss)\n",
    "\n",
    "    if acceptance(current_loss, next_loss, t, d):\n",
    "      current_model = next_model\n",
    "      current_loss = next_loss\n",
    "      print('Accepted!')\n",
    "    else:\n",
    "      print('Not Accepted.')\n",
    "    print('Current Loss at end of time ', t, ' is: ', current_loss)\n",
    "\n",
    "    losses.append(current_loss)\n",
    "    torch.save(current_model.state_dict(), '/pvc-lukemcdermott/SA_' + name + '_t_' + str(t)) \n",
    "  return losses, current_model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
